{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df52e974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt-dlp in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (2025.10.14)\n",
      "Requirement already satisfied: pandas in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: tqdm in /home/yuliana/.local/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: nltk in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: spacy in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (3.8.7)\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/yuliana/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: click in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (0.19.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/yuliana/.local/lib/python3.12/site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/yuliana/.local/lib/python3.12/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/yuliana/.local/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/yuliana/.local/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/yuliana/.local/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/yuliana/.local/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/yuliana/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/yuliana/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.2.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
      "Requirement already satisfied: wrapt in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/yuliana/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/yuliana/.local/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/yuliana/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install yt-dlp pandas tqdm nltk spacy emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2835d7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a08305d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92cb594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"youtube_comments.csv\"\n",
    "OUTPUT_FILE = \"youtube_comments_preprocessed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "146989cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 77912 comments.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_FILE)\n",
    "print(f\"Loaded {len(df)} comments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1407d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"comment\"] = df[\"comment\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a760a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(text):\n",
    "    \"\"\"Extract all emojis from the comment.\"\"\"\n",
    "    return \"\".join(ch for ch in text if ch in emoji.EMOJI_DATA)\n",
    "\n",
    "def remove_emojis(text):\n",
    "    \"\"\"Remove emojis from the comment.\"\"\"\n",
    "    return emoji.replace_emoji(text, replace='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "453925fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting emojis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77912/77912 [00:00<00:00, 155971.03it/s]\n",
      "100%|██████████| 77912/77912 [00:00<00:00, 1461321.74it/s]\n",
      "100%|██████████| 77912/77912 [00:10<00:00, 7140.79it/s] \n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting emojis...\")\n",
    "tqdm.pandas()\n",
    "df[\"emojis\"] = df[\"comment\"].progress_apply(extract_emojis)\n",
    "df[\"has_emoji\"] = df[\"emojis\"].progress_apply(lambda x: len(x) > 0)\n",
    "df[\"comment_noemoji\"] = df[\"comment\"].progress_apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "543b1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comment(text):\n",
    "    \"\"\"\n",
    "    Lowercase, remove URLs, punctuation, extra spaces.\n",
    "    Keeps negations ('not', 'no').\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)      # remove URLs\n",
    "    text = re.sub(r\"[^a-z\\s']\", \" \", text)          # keep only letters and apostrophes\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()        # collapse multiple spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92191d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77912/77912 [00:00<00:00, 82493.71it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning text...\")\n",
    "df[\"clean_comment\"] = df[\"comment_noemoji\"].progress_apply(clean_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c09a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy model (en_core_web_sm)...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading spaCy model (en_core_web_sm)...\")\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "except OSError:\n",
    "    from spacy.cli import download\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebf51894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatize_comment(text):\n",
    "    \"\"\"Lemmatize words, remove stopwords and short tokens.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    lemmas = [\n",
    "        token.lemma_ for token in doc\n",
    "        if not token.is_stop and len(token) > 2\n",
    "    ]\n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3806d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizing comments (this may take a few minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77912/77912 [03:24<00:00, 380.70it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lemmatizing comments (this may take a few minutes)...\")\n",
    "df[\"lemma_comment\"] = df[\"clean_comment\"].progress_apply(lemmatize_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "052acda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete - saved to youtube_comments_preprocessed.csv\n",
      "            id                                        video_title  \\\n",
      "0  ttjz6pax5A8  Trump reportedly rejected Zelenskyy's request ...   \n",
      "1  ttjz6pax5A8  Trump reportedly rejected Zelenskyy's request ...   \n",
      "2  ttjz6pax5A8  Trump reportedly rejected Zelenskyy's request ...   \n",
      "\n",
      "                                             comment  \\\n",
      "0  When it's TACOS turn NOBODY WILL BE ON HIS SID...   \n",
      "1  Why is Rachel on tv with that voice. Who does ...   \n",
      "2       Трамп навсегда останется марионеткой Путина!   \n",
      "\n",
      "                                           url emojis  has_emoji  \\\n",
      "0  https://www.youtube.com/watch?v=ttjz6pax5A8             False   \n",
      "1  https://www.youtube.com/watch?v=ttjz6pax5A8             False   \n",
      "2  https://www.youtube.com/watch?v=ttjz6pax5A8             False   \n",
      "\n",
      "                                     comment_noemoji  \\\n",
      "0  When it's TACOS turn NOBODY WILL BE ON HIS SID...   \n",
      "1  Why is Rachel on tv with that voice. Who does ...   \n",
      "2       Трамп навсегда останется марионеткой Путина!   \n",
      "\n",
      "                                       clean_comment  \\\n",
      "0  when it's tacos turn nobody will be on his sid...   \n",
      "1  why is rachel on tv with that voice who does s...   \n",
      "2                                                      \n",
      "\n",
      "                                       lemma_comment  \n",
      "0  taco turn foxfakebabble come go commit crime f...  \n",
      "1                                  rachel voice know  \n",
      "2                                                     \n"
     ]
    }
   ],
   "source": [
    "df.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\", lineterminator=\"\\n\")\n",
    "print(f\"Preprocessing complete - saved to {OUTPUT_FILE}\")\n",
    "print(df.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
